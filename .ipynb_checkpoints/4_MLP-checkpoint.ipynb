{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/HR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>part</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years   part  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_montly_hours   14999 non-null  int64  \n",
      " 4   time_spend_company     14999 non-null  int64  \n",
      " 5   Work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   part                   14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sales', 'accounting', 'hr', 'technical', 'support', 'management',\n",
       "       'IT', 'product_mng', 'marketing', 'RandD'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.part.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'medium', 'high'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.salary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary  part       \n",
       "high    IT               83\n",
       "        RandD            51\n",
       "        accounting       74\n",
       "        hr               45\n",
       "        management      225\n",
       "        marketing        80\n",
       "        product_mng      68\n",
       "        sales           269\n",
       "        support         141\n",
       "        technical       201\n",
       "low     IT              609\n",
       "        RandD           364\n",
       "        accounting      358\n",
       "        hr              335\n",
       "        management      180\n",
       "        marketing       402\n",
       "        product_mng     451\n",
       "        sales          2099\n",
       "        support        1146\n",
       "        technical      1372\n",
       "medium  IT              535\n",
       "        RandD           372\n",
       "        accounting      335\n",
       "        hr              359\n",
       "        management      225\n",
       "        marketing       376\n",
       "        product_mng     383\n",
       "        sales          1772\n",
       "        support         942\n",
       "        technical      1147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['salary','part']).size()#分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))#独热编码one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.part))#独热编码one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>...</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>accounting</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       272                   4              0     1   \n",
       "3                       223                   5              0     1   \n",
       "4                       159                   3              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14994                   151                   3              0     1   \n",
       "14995                   160                   3              0     1   \n",
       "14996                   143                   3              0     1   \n",
       "14997                   280                   4              0     1   \n",
       "14998                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years  high  low  ...  IT  RandD  accounting  hr  \\\n",
       "0                          0     0    1  ...   0      0           0   0   \n",
       "1                          0     0    0  ...   0      0           0   0   \n",
       "2                          0     0    0  ...   0      0           0   0   \n",
       "3                          0     0    1  ...   0      0           0   0   \n",
       "4                          0     0    1  ...   0      0           0   0   \n",
       "...                      ...   ...  ...  ...  ..    ...         ...  ..   \n",
       "14994                      0     0    1  ...   0      0           0   0   \n",
       "14995                      0     0    1  ...   0      0           0   0   \n",
       "14996                      0     0    1  ...   0      0           0   0   \n",
       "14997                      0     0    1  ...   0      0           0   0   \n",
       "14998                      0     0    1  ...   0      0           0   0   \n",
       "\n",
       "       management  marketing  product_mng  sales  support  technical  \n",
       "0               0          0            0      1        0          0  \n",
       "1               0          0            0      1        0          0  \n",
       "2               0          0            0      1        0          0  \n",
       "3               0          0            0      1        0          0  \n",
       "4               0          0            0      1        0          0  \n",
       "...           ...        ...          ...    ...      ...        ...  \n",
       "14994           0          0            0      0        1          0  \n",
       "14995           0          0            0      0        1          0  \n",
       "14996           0          0            0      0        1          0  \n",
       "14997           0          0            0      0        1          0  \n",
       "14998           0          0            0      0        1          0  \n",
       "\n",
       "[14999 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.left.value_counts()#统计left不同值的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = data.left.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.from_numpy(Y_data).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data= data[[c for c in data.columns if c !='left']].values#列表推导式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_data).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14999, 20])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14999, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义模型：  \n",
    "__int__: 初始化所有的层  \n",
    "forward：定义模型的运算过程（前向传播过程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):                        #不是model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)       #输入20输出64\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)        #逻辑回归最终输出为1\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,input):\n",
    "        x = self.linear_1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_3(input)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改写模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):                        #不是model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(20,64)       #输入20输出64\n",
    "        self.linear_2 = nn.Linear(64,64)\n",
    "        self.linear_3 = nn.Linear(64,1)        #逻辑回归最终输出为1\n",
    "    def forward(self,input):\n",
    "        x = F.relu(self.linear_1(input))\n",
    "        x = F.relu((self.linear_2(x)))\n",
    "        x = F.sigmoid((self.linear_3(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear_1): Linear(in_features=20, out_features=64, bias=True)\n",
       "  (linear_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (linear_3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt = torch.optim.Adam(model.parameters(),lr=learning)\n",
    "    return model,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model ,optim = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "no_of_batches = len(data)//batch\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.6517677307128906\n",
      "epoch 1 loss 0.6328500509262085\n",
      "epoch 2 loss 0.6066632866859436\n",
      "epoch 3 loss 0.6210174560546875\n",
      "epoch 4 loss 0.6215699315071106\n",
      "epoch 5 loss 0.6419370174407959\n",
      "epoch 6 loss 0.6626371741294861\n",
      "epoch 7 loss 0.6785110831260681\n",
      "epoch 8 loss 0.678658127784729\n",
      "epoch 9 loss 0.637440025806427\n",
      "epoch 10 loss 0.5863925814628601\n",
      "epoch 11 loss 0.5622736811637878\n",
      "epoch 12 loss 0.5515379309654236\n",
      "epoch 13 loss 0.5491669774055481\n",
      "epoch 14 loss 0.5489397644996643\n",
      "epoch 15 loss 0.5491471290588379\n",
      "epoch 16 loss 0.5493814945220947\n",
      "epoch 17 loss 0.5494246482849121\n",
      "epoch 18 loss 0.5494822859764099\n",
      "epoch 19 loss 0.549614429473877\n",
      "epoch 20 loss 0.5495252013206482\n",
      "epoch 21 loss 0.5496603846549988\n",
      "epoch 22 loss 0.5495318174362183\n",
      "epoch 23 loss 0.5495581030845642\n",
      "epoch 24 loss 0.5495593547821045\n",
      "epoch 25 loss 0.5495425462722778\n",
      "epoch 26 loss 0.5496588349342346\n",
      "epoch 27 loss 0.5496343374252319\n",
      "epoch 28 loss 0.5489358901977539\n",
      "epoch 29 loss 0.5490612387657166\n",
      "epoch 30 loss 0.5491858720779419\n",
      "epoch 31 loss 0.5494130849838257\n",
      "epoch 32 loss 0.5493773818016052\n",
      "epoch 33 loss 0.5495601296424866\n",
      "epoch 34 loss 0.5495243072509766\n",
      "epoch 35 loss 0.5522223114967346\n",
      "epoch 36 loss 0.5508797764778137\n",
      "epoch 37 loss 0.5501837134361267\n",
      "epoch 38 loss 0.5497646927833557\n",
      "epoch 39 loss 0.5496373772621155\n",
      "epoch 40 loss 0.5496801733970642\n",
      "epoch 41 loss 0.5495426058769226\n",
      "epoch 42 loss 0.5495557188987732\n",
      "epoch 43 loss 0.5496162176132202\n",
      "epoch 44 loss 0.5494853258132935\n",
      "epoch 45 loss 0.5494214296340942\n",
      "epoch 46 loss 0.5495343804359436\n",
      "epoch 47 loss 0.5494961142539978\n",
      "epoch 48 loss 0.5493813753128052\n",
      "epoch 49 loss 0.5493494272232056\n",
      "epoch 50 loss 0.5494693517684937\n",
      "epoch 51 loss 0.5494272112846375\n",
      "epoch 52 loss 0.5493607521057129\n",
      "epoch 53 loss 0.5493184328079224\n",
      "epoch 54 loss 0.5495084524154663\n",
      "epoch 55 loss 0.5493949055671692\n",
      "epoch 56 loss 0.5493491291999817\n",
      "epoch 57 loss 0.549474835395813\n",
      "epoch 58 loss 0.5494305491447449\n",
      "epoch 59 loss 0.549321711063385\n",
      "epoch 60 loss 0.5492798686027527\n",
      "epoch 61 loss 0.5494013428688049\n",
      "epoch 62 loss 0.5493780374526978\n",
      "epoch 63 loss 0.5493226647377014\n",
      "epoch 64 loss 0.5493042469024658\n",
      "epoch 65 loss 0.5492779612541199\n",
      "epoch 66 loss 0.5492165088653564\n",
      "epoch 67 loss 0.5492087602615356\n",
      "epoch 68 loss 0.5492165684700012\n",
      "epoch 69 loss 0.5492715835571289\n",
      "epoch 70 loss 0.5492805242538452\n",
      "epoch 71 loss 0.5492909550666809\n",
      "epoch 72 loss 0.5492779612541199\n",
      "epoch 73 loss 0.5492165684700012\n",
      "epoch 74 loss 0.5494168400764465\n",
      "epoch 75 loss 0.5493847131729126\n",
      "epoch 76 loss 0.5493794679641724\n",
      "epoch 77 loss 0.5493484139442444\n",
      "epoch 78 loss 0.5492658615112305\n",
      "epoch 79 loss 0.5492312908172607\n",
      "epoch 80 loss 0.5492196679115295\n",
      "epoch 81 loss 0.5494153499603271\n",
      "epoch 82 loss 0.5493324995040894\n",
      "epoch 83 loss 0.5493686199188232\n",
      "epoch 84 loss 0.5492801666259766\n",
      "epoch 85 loss 0.5492470264434814\n",
      "epoch 86 loss 0.549233615398407\n",
      "epoch 87 loss 0.549148678779602\n",
      "epoch 88 loss 0.5493435263633728\n",
      "epoch 89 loss 0.5493258833885193\n",
      "epoch 90 loss 0.5492892265319824\n",
      "epoch 91 loss 0.5491955876350403\n",
      "epoch 92 loss 0.5492318868637085\n",
      "epoch 93 loss 0.5491427183151245\n",
      "epoch 94 loss 0.5492852330207825\n",
      "epoch 95 loss 0.5493214130401611\n",
      "epoch 96 loss 0.5492307543754578\n",
      "epoch 97 loss 0.5491849184036255\n",
      "epoch 98 loss 0.5491656064987183\n",
      "epoch 99 loss 0.5493596196174622\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        start = i*batch\n",
    "        end = start + batch\n",
    "        x = X[start:end]\n",
    "        y = Y[start:end]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch',epoch,'loss',loss_fn(model(X),Y).data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(X),Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用dataset类进行重构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRdataset = TensorDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x17ecd99b160>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HRdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(HRdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1000e-01, 8.8000e-01, 7.0000e+00, 2.7200e+02, 4.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [7.2000e-01, 8.7000e-01, 5.0000e+00, 2.2300e+02, 5.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.7000e-01, 5.2000e-01, 2.0000e+00, 1.5900e+02, 3.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HRdataset[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model ,optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.3090405464172363\n",
      "epoch 1 loss 0.656341552734375\n",
      "epoch 2 loss 0.7114343643188477\n",
      "epoch 3 loss 0.6161794662475586\n",
      "epoch 4 loss 0.5996212363243103\n",
      "epoch 5 loss 0.5984593629837036\n",
      "epoch 6 loss 0.570859968662262\n",
      "epoch 7 loss 0.5665850639343262\n",
      "epoch 8 loss 0.5560582876205444\n",
      "epoch 9 loss 0.5513117909431458\n",
      "epoch 10 loss 0.5494293570518494\n",
      "epoch 11 loss 0.5488953590393066\n",
      "epoch 12 loss 0.5487821102142334\n",
      "epoch 13 loss 0.556087851524353\n",
      "epoch 14 loss 0.5502253174781799\n",
      "epoch 15 loss 0.5491610169410706\n",
      "epoch 16 loss 0.5487828850746155\n",
      "epoch 17 loss 0.5489980578422546\n",
      "epoch 18 loss 0.5489639639854431\n",
      "epoch 19 loss 0.5492517948150635\n",
      "epoch 20 loss 0.5492337346076965\n",
      "epoch 21 loss 0.5493215918540955\n",
      "epoch 22 loss 0.5492203235626221\n",
      "epoch 23 loss 0.549416720867157\n",
      "epoch 24 loss 0.5493143796920776\n",
      "epoch 25 loss 0.5493703484535217\n",
      "epoch 26 loss 0.5494309067726135\n",
      "epoch 27 loss 0.5493703484535217\n",
      "epoch 28 loss 0.5493376851081848\n",
      "epoch 29 loss 0.5492523908615112\n",
      "epoch 30 loss 0.5492715835571289\n",
      "epoch 31 loss 0.5494118332862854\n",
      "epoch 32 loss 0.5493814945220947\n",
      "epoch 33 loss 0.549340546131134\n",
      "epoch 34 loss 0.5492553114891052\n",
      "epoch 35 loss 0.5492393970489502\n",
      "epoch 36 loss 0.5492005944252014\n",
      "epoch 37 loss 0.5493454933166504\n",
      "epoch 38 loss 0.5493706464767456\n",
      "epoch 39 loss 0.549278199672699\n",
      "epoch 40 loss 0.5491864085197449\n",
      "epoch 41 loss 0.5492095947265625\n",
      "epoch 42 loss 0.549347996711731\n",
      "epoch 43 loss 0.5493137240409851\n",
      "epoch 44 loss 0.5493040680885315\n",
      "epoch 45 loss 0.5492783784866333\n",
      "epoch 46 loss 0.5492165684700012\n",
      "epoch 47 loss 0.5491950511932373\n",
      "epoch 48 loss 0.5491816997528076\n",
      "epoch 49 loss 0.5492232441902161\n",
      "epoch 50 loss 0.5491427183151245\n",
      "epoch 51 loss 0.54933762550354\n",
      "epoch 52 loss 0.5493261814117432\n",
      "epoch 53 loss 0.5492921471595764\n",
      "epoch 54 loss 0.5492088794708252\n",
      "epoch 55 loss 0.5491235852241516\n",
      "epoch 56 loss 0.5491606593132019\n",
      "epoch 57 loss 0.549301028251648\n",
      "epoch 58 loss 0.5492643713951111\n",
      "epoch 59 loss 0.549252450466156\n",
      "epoch 60 loss 0.5492090582847595\n",
      "epoch 61 loss 0.5491242408752441\n",
      "epoch 62 loss 0.5491548180580139\n",
      "epoch 63 loss 0.5492991209030151\n",
      "epoch 64 loss 0.549214243888855\n",
      "epoch 65 loss 0.54924476146698\n",
      "epoch 66 loss 0.5491600036621094\n",
      "epoch 67 loss 0.5491162538528442\n",
      "epoch 68 loss 0.5491028428077698\n",
      "epoch 69 loss 0.5492894053459167\n",
      "epoch 70 loss 0.549205482006073\n",
      "epoch 71 loss 0.5491921305656433\n",
      "epoch 72 loss 0.5491496920585632\n",
      "epoch 73 loss 0.5490557551383972\n",
      "epoch 74 loss 0.54908686876297\n",
      "epoch 75 loss 0.5492302775382996\n",
      "epoch 76 loss 0.5492145419120789\n",
      "epoch 77 loss 0.5491740703582764\n",
      "epoch 78 loss 0.549079954624176\n",
      "epoch 79 loss 0.5491088032722473\n",
      "epoch 80 loss 0.549251914024353\n",
      "epoch 81 loss 0.5491607785224915\n",
      "epoch 82 loss 0.5491850972175598\n",
      "epoch 83 loss 0.5490939617156982\n",
      "epoch 84 loss 0.549008309841156\n",
      "epoch 85 loss 0.5490356087684631\n",
      "epoch 86 loss 0.5491684675216675\n",
      "epoch 87 loss 0.5491986870765686\n",
      "epoch 88 loss 0.5491054058074951\n",
      "epoch 89 loss 0.5490093231201172\n",
      "epoch 90 loss 0.5490381717681885\n",
      "epoch 91 loss 0.5491729974746704\n",
      "epoch 92 loss 0.5491473078727722\n",
      "epoch 93 loss 0.5490554571151733\n",
      "epoch 94 loss 0.5490102767944336\n",
      "epoch 95 loss 0.5489802956581116\n",
      "epoch 96 loss 0.5491204261779785\n",
      "epoch 97 loss 0.5491371154785156\n",
      "epoch 98 loss 0.5490450859069824\n",
      "epoch 99 loss 0.5490231513977051\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        #start = i*batch\n",
    "        #end = start + batch\n",
    "        #x = X[start:end]\n",
    "        #y = Y[start:end]\n",
    "        x,y = HRdataset[i*batch:i*batch+batch]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch',epoch,'loss',loss_fn(model(X),Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_ds = TensorDataset(X,Y)\n",
    "HR_dl = DataLoader(HR_ds,batch_size=batch,shuffle=True)   #shuffle代表是否乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model ,optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch  0  loss  0.5421498417854309\n",
      " epoch  1  loss  0.487394243478775\n",
      " epoch  2  loss  0.41612812876701355\n",
      " epoch  3  loss  0.3603520691394806\n",
      " epoch  4  loss  0.3365791440010071\n",
      " epoch  5  loss  0.35680532455444336\n",
      " epoch  6  loss  0.3316398561000824\n",
      " epoch  7  loss  0.2971959412097931\n",
      " epoch  8  loss  0.39583131670951843\n",
      " epoch  9  loss  0.29951757192611694\n",
      " epoch  10  loss  0.2697335481643677\n",
      " epoch  11  loss  0.275526225566864\n",
      " epoch  12  loss  0.28338876366615295\n",
      " epoch  13  loss  0.26777610182762146\n",
      " epoch  14  loss  0.2755805253982544\n",
      " epoch  15  loss  0.25642988085746765\n",
      " epoch  16  loss  0.2510848343372345\n",
      " epoch  17  loss  0.24875856935977936\n",
      " epoch  18  loss  0.2369304597377777\n",
      " epoch  19  loss  0.24299103021621704\n",
      " epoch  20  loss  0.22872112691402435\n",
      " epoch  21  loss  0.24013322591781616\n",
      " epoch  22  loss  0.2642103135585785\n",
      " epoch  23  loss  0.22926226258277893\n",
      " epoch  24  loss  0.23537151515483856\n",
      " epoch  25  loss  0.22110897302627563\n",
      " epoch  26  loss  0.21804878115653992\n",
      " epoch  27  loss  0.2221122682094574\n",
      " epoch  28  loss  0.19955980777740479\n",
      " epoch  29  loss  0.23807360231876373\n",
      " epoch  30  loss  0.19443680346012115\n",
      " epoch  31  loss  0.1986650824546814\n",
      " epoch  32  loss  0.19294443726539612\n",
      " epoch  33  loss  0.20151177048683167\n",
      " epoch  34  loss  0.19038988649845123\n",
      " epoch  35  loss  0.1874774694442749\n",
      " epoch  36  loss  0.18592193722724915\n",
      " epoch  37  loss  0.22882547974586487\n",
      " epoch  38  loss  0.24599267542362213\n",
      " epoch  39  loss  0.19045068323612213\n",
      " epoch  40  loss  0.18099115788936615\n",
      " epoch  41  loss  0.1799018830060959\n",
      " epoch  42  loss  0.1848224252462387\n",
      " epoch  43  loss  0.1712048351764679\n",
      " epoch  44  loss  0.16513115167617798\n",
      " epoch  45  loss  0.19375428557395935\n",
      " epoch  46  loss  0.1691218912601471\n",
      " epoch  47  loss  0.1596371978521347\n",
      " epoch  48  loss  0.15633942186832428\n",
      " epoch  49  loss  0.1628270149230957\n",
      " epoch  50  loss  0.14471593499183655\n",
      " epoch  51  loss  0.16284123063087463\n",
      " epoch  52  loss  0.14325100183486938\n",
      " epoch  53  loss  0.13400228321552277\n",
      " epoch  54  loss  0.14361274242401123\n",
      " epoch  55  loss  0.1548255831003189\n",
      " epoch  56  loss  0.1307026445865631\n",
      " epoch  57  loss  0.13141430914402008\n",
      " epoch  58  loss  0.15380316972732544\n",
      " epoch  59  loss  0.13961602747440338\n",
      " epoch  60  loss  0.12086497247219086\n",
      " epoch  61  loss  0.12815289199352264\n",
      " epoch  62  loss  0.12214373797178268\n",
      " epoch  63  loss  0.11915764212608337\n",
      " epoch  64  loss  0.11929567903280258\n",
      " epoch  65  loss  0.12488146871328354\n",
      " epoch  66  loss  0.1223430410027504\n",
      " epoch  67  loss  0.1222347766160965\n",
      " epoch  68  loss  0.11330243200063705\n",
      " epoch  69  loss  0.11472160369157791\n",
      " epoch  70  loss  0.11516574025154114\n",
      " epoch  71  loss  0.12165312469005585\n",
      " epoch  72  loss  0.11593428254127502\n",
      " epoch  73  loss  0.11440794914960861\n",
      " epoch  74  loss  0.12241002172231674\n",
      " epoch  75  loss  0.1157444640994072\n",
      " epoch  76  loss  0.1140451580286026\n",
      " epoch  77  loss  0.11664437502622604\n",
      " epoch  78  loss  0.1315707266330719\n",
      " epoch  79  loss  0.13258464634418488\n",
      " epoch  80  loss  0.11933531612157822\n",
      " epoch  81  loss  0.1111878752708435\n",
      " epoch  82  loss  0.11943212151527405\n",
      " epoch  83  loss  0.13226015865802765\n",
      " epoch  84  loss  0.13530972599983215\n",
      " epoch  85  loss  0.1207956001162529\n",
      " epoch  86  loss  0.1261729598045349\n",
      " epoch  87  loss  0.11988530308008194\n",
      " epoch  88  loss  0.11391595005989075\n",
      " epoch  89  loss  0.11209255456924438\n",
      " epoch  90  loss  0.13668109476566315\n",
      " epoch  91  loss  0.12033180147409439\n",
      " epoch  92  loss  0.10774870961904526\n",
      " epoch  93  loss  0.10523978620767593\n",
      " epoch  94  loss  0.11348562687635422\n",
      " epoch  95  loss  0.11141078174114227\n",
      " epoch  96  loss  0.11772219836711884\n",
      " epoch  97  loss  0.11262442916631699\n",
      " epoch  98  loss  0.10600747168064117\n",
      " epoch  99  loss  0.11335072666406631\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x,y in HR_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print(' epoch ',epoch,' loss ',loss_fn(model(X),Y).data.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加验证  \n",
    "## 了解过拟合与欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.mirrors.ustc.edu.cn/simple\n",
      "Collecting sklearn\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/3c/d3/63700971e89bc5024d4356310229f5cdc93927c8c8bf95c53bb7b5e4a62e/scikit_learn-0.24.1-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\anaconda\\envs\\pytorch\\lib\\site-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/f3/9f/80522344838ae24cac9e945240436269cbb92349f7f1f4c9dfc10cb6bad5/scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=f3acbc798583ea4507907389bc2694b63365fcf2b0dc6d072a98f4ec315ed86b\n",
      "  Stored in directory: c:\\users\\x-y\\appdata\\local\\pip\\cache\\wheels\\42\\0a\\f1\\2a82117115c6d0f91162b9122b3dfcc228bc4e225f60cb2666\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(X_data,Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 20)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11249, 20), (3750, 20))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x).type(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32)\n",
    "test_x = torch.from_numpy(test_x).type(torch.float32)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_x,train_y)\n",
    "train_dl = DataLoader(train_ds,batch_size=batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TensorDataset(train_x,train_y)\n",
    "test_dl = DataLoader(train_ds,batch_size=batch)  #测试集不需要乱序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何计算正确率？"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "(y_pred == labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model ,optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Int but got scalar type Float for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-02c8a4f3593e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mepoch_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mepoch_test_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-be12476ec534>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Int but got scalar type Float for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x,y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_accuracy = accuracy(model(train_x),train_y)\n",
    "        epoch_loss = loss_fn(model(train_x),train_y).data\n",
    "        epoch_test_accuracy = accuracy(model(test_x),test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x),test_y).data\n",
    "        print(' epoch ',epoch,\n",
    "              ' loss ',round(epoch_loss.item(),3),\n",
    "              ' accuracy ',round(epoch_accuracy.item(),3),\n",
    "              ' test_loss ',round(epoch_test_loss.item(),3),\n",
    "              ' test_accuracy ',round(epoch_test_accuracy.item(),3)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
